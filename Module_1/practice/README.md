# Практическая работа 1.2. Обзор структур хранения и выбор оптимальной

## Общая информация

| Параметр | Значение |
|---|---|
| **Модуль** | 1. Введение в моделирование и анализ данных |
| **Тема** | 1.2. Типы данных и структуры хранения |
| **Длительность** | 60–90 минут |
| **Формат** | Индивидуальная работа / работа в парах |
| **Среда** | Yandex Cloud (Managed PostgreSQL) |

## Цель работы

Сравнить три структуры хранения данных — **CSV**, **PostgreSQL (RDBMS)** и **JSON** — выполняя одинаковые операции с реальными данными горнодобывающего предприятия «Руда+». По итогам работы вы заполните сравнительную таблицу и обоснуете, какая структура хранения оптимальна для каждого типа данных.

## Описание предметной области

**Предприятие «Руда+»** занимается добычей железной руды в подземных шахтах. В рамках внедрения MES-системы необходимо организовать хранение и анализ данных о:

- **Оборудовании**: погрузочно-доставочные машины (ПДМ), шахтные самосвалы, вагонетки, скиповые подъёмники
- **Телеметрии**: показания датчиков (температура, давление, вибрация, масса груза, скорость)
- **Добыче**: журнал добычи руды по сменам с качественными характеристиками (содержание Fe, влажность)
- **Простоях**: журнал плановых и незапланированных остановок оборудования

## Подготовленные материалы

```
practice/
├── README.md                          ← вы читаете этот файл
├── data/
│   ├── equipment.csv                  ← справочник оборудования (12 записей)
│   ├── sensor_readings.csv            ← показания датчиков (50 записей)
│   ├── ore_production.csv             ← журнал добычи (15 записей)
│   ├── downtime_events.csv            ← журнал простоев (10 записей)
│   ├── equipment.json                 ← оборудование в JSON (3 документа)
│   └── sensor_event.json              ← событие аварии в JSON (1 документ)
└── scripts/
    ├── 01_create_tables.sql           ← DDL: создание таблиц
    ├── 02_load_data.sql               ← загрузка данных (INSERT)
    └── 03_queries.sql                 ← аналитические SQL-запросы
```

---

## Часть 1. Работа с CSV (20 минут)

### Шаг 1.1. Откройте CSV-файлы и изучите структуру

1. Откройте файл `data/equipment.csv` в текстовом редакторе или Excel
2. Ответьте на вопросы:
   - Сколько колонок в файле?
   - Какие типы данных можно определить визуально (числа, строки, даты)?
   - Есть ли пропущенные значения?
   - Какой разделитель используется?

### Шаг 1.2. Ручной анализ CSV

Откройте файл `data/ore_production.csv` и попробуйте **вручную** ответить на вопросы:

1. Какая общая добыча руды за 10 февраля 2026 года?
2. Какое среднее содержание железа (Fe) по типу руды «Магнетит»?
3. Сколько смен было прервано (статус «Прервана»)?

> **Запишите время**, которое потребовалось на ответы. Зафиксируйте трудности.

### Шаг 1.3. Попробуйте выполнить операцию JOIN

Откройте одновременно `data/ore_production.csv` и `data/downtime_events.csv`.

**Задание:** Найдите связь между прерванной сменой (PRD-010) и соответствующим событием простоя для оборудования EQ-001.

> **Вопрос для размышления:** Насколько удобно связывать данные из разных CSV-файлов? Какие проблемы вы заметили?

### Шаг 1.4. Оцените CSV-формат

Заполните первую колонку в сравнительной таблице (см. [Итоговая таблица](#итоговая-сравнительная-таблица) в конце документа).

---

## Часть 2. Работа с PostgreSQL (40 минут)

### Шаг 2.1. Подключение к базе данных

#### Вариант А: Yandex Cloud (Managed PostgreSQL)

1. Войдите в [консоль Yandex Cloud](https://console.yandex.cloud/)
2. Перейдите в сервис **Managed Service for PostgreSQL**
3. Выберите кластер, созданный для курса
4. Откройте **SQL-редактор** (WebSQL) или подключитесь через утилиту `psql`:

```bash
psql "host=<хост-кластера> \
      port=6432 \
      dbname=ruda_plus_db \
      user=student \
      sslmode=verify-full"
```

#### Вариант Б: Локальный PostgreSQL

Если у вас установлен PostgreSQL локально:

```bash
psql -U postgres -d postgres
```

```sql
-- Создайте базу данных
CREATE DATABASE ruda_plus_db;

-- Подключитесь к ней
\c ruda_plus_db
```

### Шаг 2.2. Создание таблиц

1. Откройте файл `scripts/01_create_tables.sql`
2. Изучите структуру таблиц. Обратите внимание на:
   - Типы данных (`VARCHAR`, `NUMERIC`, `DATE`, `TIMESTAMP`)
   - Ограничения (`PRIMARY KEY`, `REFERENCES`, `CHECK`)
   - Комментарии (`COMMENT ON`)
   - Индексы (`CREATE INDEX`)
3. Выполните скрипт:

```sql
-- Весь скрипт целиком
\i scripts/01_create_tables.sql
```

Или скопируйте содержимое скрипта и вставьте в SQL-редактор.

4. Убедитесь, что таблицы созданы:

```sql
SET search_path TO ruda_plus, public;

SELECT table_name,
       (SELECT COUNT(*) FROM information_schema.columns c
        WHERE c.table_schema = 'ruda_plus' AND c.table_name = t.table_name) AS columns_count
FROM information_schema.tables t
WHERE table_schema = 'ruda_plus'
ORDER BY table_name;
```

### Шаг 2.3. Загрузка данных

1. Выполните скрипт `scripts/02_load_data.sql`
2. Проверьте результат — в конце скрипта есть проверочный запрос. Ожидаемый результат:

| table_name | row_count |
|---|---|
| equipment | 12 |
| sensor_readings | 50 |
| ore_production | 15 |
| downtime_events | 10 |

### Шаг 2.4. Выполнение аналитических запросов

Откройте файл `scripts/03_queries.sql` и **последовательно** выполняйте запросы из каждой части. После каждого запроса изучите результат.

#### Часть 1: Справочник оборудования

Выполните запросы 1.1–1.3 и ответьте:

- Каких типов оборудования на предприятии больше всего?
- Какому оборудованию ближайшее ТО уже просрочено?
- У какого производителя наибольшая средняя наработка?

#### Часть 2: Телеметрия

Выполните запросы 2.1–2.3 и ответьте:

- Какой тип датчика чаще всего генерирует предупреждения?
- Проследите динамику температуры ПДМ-01 — видно ли нарастание проблемы?
- За какой период температура выросла с нормы до аварийного значения?

#### Часть 3: Добыча руды

Выполните запросы 3.1–3.3 и ответьте:

- Какая шахта добывает больше руды?
- Кто из операторов наиболее производительный?
- У какого типа руды выше содержание железа?

#### Часть 4: Простои

Выполните запросы 4.1–4.2 и ответьте:

- Какова доля незапланированных простоев (в часах)?
- Какое оборудование чаще всего ломается?
- Какая категория поломок преобладает?

#### Часть 5: Комплексные запросы

Выполните запросы 5.1–5.2. Это ключевые запросы — они показывают **силу реляционной модели**:

- Запрос 5.1 объединяет показания датчиков и события простоев для ПДМ-01 в единую хронологию. Видно, как предупреждения датчиков предшествовали поломке.
- Запрос 5.2 связывает добычу с простоями через `LEFT JOIN` — видно, как поломка привела к прерванной смене с нулевой добычей.

> **Вопрос:** Попробуйте представить, как эти запросы выглядели бы при работе только с CSV-файлами. Реалистично ли это?

### Шаг 2.5. Самостоятельные запросы

Напишите самостоятельно:

**Запрос А.** Найдите оборудование, у которого наработка двигателя превышает 15000 моточасов и которое произведено ранее 2020 года. Это кандидаты на замену.

<details>
<summary>Подсказка</summary>

```sql
SELECT equipment_id, equipment_name, manufacturer, model,
       year_manufactured, engine_hours
FROM ruda_plus.equipment
WHERE engine_hours > 15000
  AND year_manufactured < 2020;
```
</details>

**Запрос Б.** Рассчитайте среднюю добычу за смену для каждой единицы оборудования (только завершённые смены). Добавьте название оборудования через JOIN.

<details>
<summary>Подсказка</summary>

```sql
SELECT e.equipment_name, e.equipment_type,
       COUNT(*) AS shifts,
       ROUND(AVG(p.tonnage_extracted), 1) AS avg_tonnage
FROM ruda_plus.ore_production p
JOIN ruda_plus.equipment e ON p.equipment_id = e.equipment_id
WHERE p.status = 'Завершена'
GROUP BY e.equipment_name, e.equipment_type
ORDER BY avg_tonnage DESC;
```
</details>

**Запрос В.** Найдите все показания датчиков с флагом ALARM, и для каждого покажите: через сколько минут после первого WARN наступил ALARM (для того же оборудования и типа датчика).

<details>
<summary>Подсказка</summary>

```sql
WITH warn_times AS (
    SELECT equipment_id, sensor_type,
           MIN(reading_timestamp) AS first_warn
    FROM ruda_plus.sensor_readings
    WHERE quality_flag = 'WARN'
    GROUP BY equipment_id, sensor_type
)
SELECT sr.equipment_id, sr.sensor_type,
       wt.first_warn,
       sr.reading_timestamp AS alarm_time,
       EXTRACT(EPOCH FROM (sr.reading_timestamp - wt.first_warn)) / 60 AS minutes_warn_to_alarm
FROM ruda_plus.sensor_readings sr
JOIN warn_times wt
  ON sr.equipment_id = wt.equipment_id
 AND sr.sensor_type = wt.sensor_type
WHERE sr.quality_flag = 'ALARM';
```
</details>

### Шаг 2.6. Оцените PostgreSQL

Заполните вторую колонку в сравнительной таблице.

---

## Часть 3. Работа с JSON (20 минут)

### Шаг 3.1. Изучите JSON-документ оборудования

1. Откройте файл `data/equipment.json`
2. Обратите внимание на особенности, которых **нет в CSV и SQL**:
   - **Вложенные объекты**: `location.gps_coordinates`, `maintenance.maintenance_history`
   - **Массивы**: `sensors[]`, `tags[]`
   - **Разнородная структура**: у ПДМ — `bucket_capacity_m3`, у самосвала — `body_capacity_m3`, у подъёмника — `shaft_depth_m`
   - **Опциональные поля**: `alarm_threshold: null` для навигации

3. Ответьте на вопросы:
   - Сколько датчиков установлено на ПДМ-01?
   - Какой порог срабатывания ALARM для температуры двигателя у СС-01?
   - Сколько стоило последнее ТО скипового подъёмника?

### Шаг 3.2. Изучите JSON-событие аварии

1. Откройте файл `data/sensor_event.json`
2. Это пример события, которое генерируется системой мониторинга в реальном времени. Обратите внимание на:
   - Структура `alerts[]` — несколько сработавших датчиков в одном событии
   - `context.readings_history` — история показаний для анализа тренда
   - `actions` — автоматические действия системы
   - `metadata` — служебная информация

3. Ответьте: почему для таких событий JSON удобнее, чем табличная структура?

### Шаг 3.3. JSON в PostgreSQL

PostgreSQL поддерживает тип данных `JSONB`. Попробуйте выполнить следующие запросы:

```sql
-- Создаём таблицу для хранения JSON-документов оборудования
CREATE TABLE IF NOT EXISTS ruda_plus.equipment_json (
    doc_id SERIAL PRIMARY KEY,
    data   JSONB NOT NULL
);

-- Вставляем JSON-документ (скопируйте содержимое первого объекта из equipment.json)
INSERT INTO ruda_plus.equipment_json (data) VALUES (
'{
  "equipment_id": "EQ-001",
  "equipment_name": "ПДМ-01",
  "equipment_type": "Погрузочно-доставочная машина",
  "manufacturer": "Sandvik",
  "model": "LH517i",
  "status": "В работе",
  "specs": {
    "max_payload_tons": 17.0,
    "engine_power_kw": 275
  },
  "sensors": [
    {"type": "Температура двигателя", "unit": "°C", "alarm_threshold": 100},
    {"type": "Давление гидравлики", "unit": "бар", "alarm_threshold": 200},
    {"type": "Вибрация", "unit": "мм/с", "alarm_threshold": 7.0}
  ],
  "tags": ["ПДМ", "Sandvik", "Северная", "активный"]
}'::jsonb
);
```

Теперь выполните запросы к JSON-данным:

```sql
-- Извлечь название оборудования
SELECT data->>'equipment_name' AS name
FROM ruda_plus.equipment_json;

-- Извлечь вложенное поле
SELECT data->>'equipment_name' AS name,
       data->'specs'->>'max_payload_tons' AS payload,
       data->'specs'->>'engine_power_kw' AS power
FROM ruda_plus.equipment_json;

-- Получить список датчиков (развернуть массив)
SELECT data->>'equipment_name' AS equipment,
       sensor->>'type' AS sensor_type,
       sensor->>'alarm_threshold' AS threshold
FROM ruda_plus.equipment_json,
     jsonb_array_elements(data->'sensors') AS sensor;

-- Поиск по тегам
SELECT data->>'equipment_id' AS id,
       data->>'equipment_name' AS name
FROM ruda_plus.equipment_json
WHERE data->'tags' ? 'Sandvik';
```

### Шаг 3.4. Сравните подходы

Обратите внимание:
- JSON позволяет хранить **разнородные данные** в одной коллекции (ПДМ, самосвал, подъёмник — у каждого свои характеристики)
- JSON поддерживает **вложенность** (история ТО внутри документа оборудования)
- JSON **не требует миграций** при добавлении нового поля
- Но: запросы к JSON менее выразительны, нет ссылочной целостности, труднее агрегировать

Заполните третью колонку в сравнительной таблице.

---

## Итоговая сравнительная таблица

Заполните таблицу на основе выполненной работы:

| Критерий | CSV | PostgreSQL (RDBMS) | JSON |
|---|---|---|---|
| **Скорость загрузки данных** | ? | ? | ? |
| **Удобство просмотра** | ? | ? | ? |
| **Выполнение агрегаций** (SUM, AVG, COUNT) | ? | ? | ? |
| **Связывание таблиц** (JOIN) | ? | ? | ? |
| **Фильтрация по условиям** | ? | ? | ? |
| **Гибкость структуры** | ? | ? | ? |
| **Вложенные/иерархические данные** | ? | ? | ? |
| **Целостность данных** (constraints) | ? | ? | ? |
| **Масштабируемость** (миллионы записей) | ? | ? | ? |
| **Инструменты и экосистема** | ? | ? | ? |

Оценивайте по шкале: **отлично / хорошо / удовлетворительно / плохо**

---

## Итоговое задание

На основе выполненной работы ответьте на вопросы:

### 1. Выбор хранилища для MES-системы «Руда+»

Для каждого типа данных предприятия предложите оптимальную структуру хранения и обоснуйте выбор:

| Тип данных | Рекомендуемое хранилище | Обоснование |
|---|---|---|
| Справочник оборудования | ? | ? |
| Показания датчиков (телеметрия) | ? | ? |
| Журнал добычи руды | ? | ? |
| Журнал простоев | ? | ? |
| Видео с регистраторов | ? | ? |
| Данные навигационной системы | ? | ? |
| Аналитические отчёты | ? | ? |

### 2. Вопросы для обсуждения

1. Почему для одного предприятия может понадобиться **несколько** типов хранилищ?
2. Что произойдёт, если все данные хранить только в CSV-файлах при объёме 10 ГБ?
3. В каких сценариях JSON-документы предпочтительнее реляционной модели?
4. Как вы думаете, какое хранилище лучше подойдёт для **потоковых данных с датчиков** при частоте 1000 показаний/сек?

---

## Ответы на контрольные вопросы из Части 1

<details>
<summary>Раскрыть ответы</summary>

**Общая добыча за 10 февраля 2026:**
125.4 + 98.7 + 115.2 + 87.3 + 142.8 + 108.5 + 95.1 = **773.0 тонн**

Проверка SQL:
```sql
SELECT SUM(tonnage_extracted)
FROM ruda_plus.ore_production
WHERE production_date = '2026-02-10' AND status = 'Завершена';
```

**Среднее содержание Fe для магнетита:**
(32.5 + 34.1 + 31.8 + 29.7 + 33.6 + 33.2 + 30.4 + 31.1 + 33.0) / 9 = **32.16%**

**Прерванных смен:** 1 (PRD-010)

</details>
