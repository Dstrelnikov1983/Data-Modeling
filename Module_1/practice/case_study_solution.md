# Пример решения: Анализ жизненного цикла данных «Руда+»

## Сценарий

> Компания «Руда+» — добыча железной руды в шахтах. 2,2 миллиона тонн руды в год. Данные поступают из датчиков, АСУ ТП, ERP-системы. Руководство хочет построить аналитику по эффективности работы.

---

## Задание 1. Источники данных и их характеристики

### 1.1. Карта источников данных

| № | Источник | Тип системы | Тип данных | Формат | Частота | Объём | Протокол |
|---|---|---|---|---|---|---|---|
| 1 | Датчики оборудования (температура, давление, вибрация) | IoT / SCADA | Структурированные (временные ряды) | Числовые значения + timestamp | Реальное время (1–10 сек) | ~50 млн записей/день | MQTT, OPC UA |
| 2 | Навигационная система (GPS-треки ПДМ, самосвалов) | IoT | Полуструктурированные | JSON (координаты, скорость, направление) | Реальное время (1–5 сек) | ~20 млн записей/день | MQTT |
| 3 | Видеорегистраторы (бортовые камеры) | Видеонаблюдение | Неструктурированные | H.264/H.265 видеопотоки | Непрерывно | ~500 ГБ/день | RTSP |
| 4 | АСУ ТП (управление процессами) | SCADA / DCS | Структурированные | Теги и значения | Реальное время | ~10 млн записей/день | OPC UA, Modbus |
| 5 | ERP-система (1С / SAP) | ERP | Структурированные | Таблицы реляционной БД | Пакетно (по событию) | ~10 000 документов/день | REST API, файловый обмен |
| 6 | Журналы операторов (сменные рапорты) | Ручной ввод | Структурированные + полуструктурированные | Формы, Excel | 3 раза в сутки (по сменам) | ~50 записей/день | Веб-формы |
| 7 | Лабораторные анализы качества руды | LIMS | Структурированные | Таблицы (Fe%, влажность, примеси) | По пробам (10–30 в день) | ~30 записей/день | REST API, CSV |
| 8 | Система контроля доступа (СКУД) | СКУД | Структурированные | Логи проходов | По событию | ~2000 записей/день | SQL / файловый обмен |

### 1.2. Классификация по типу данных

```
                  Источники данных «Руда+»
                          │
        ┌─────────────────┼─────────────────┐
        │                 │                 │
  Структурированные  Полуструктурированные  Неструктурированные
  (~20% объёма)      (~10% объёма)          (~70% объёма)
        │                 │                 │
  ▸ Датчики (числа)  ▸ GPS-треки (JSON)  ▸ Видеопотоки
  ▸ ERP (таблицы)    ▸ Логи систем       ▸ Фото дефектов
  ▸ Лабораторные     ▸ Конфигурации      ▸ Сканы документов
  ▸ Сменные рапорты  ▸ Алерты/события    ▸ Аудиозаписи
  ▸ СКУД (логи)
```

### 1.3. Характеристики ключевых потоков данных

**Поток 1: Телеметрия оборудования (высокочастотный)**
- Источник: 50+ единиц оборудования × 5–8 датчиков на каждую
- Частота: 1 показание / 1–10 секунд
- Расчётный объём: ~300–500 показаний/сек, ~25–43 млн записей/день
- Требования: задержка < 5 секунд для мониторинга в реальном времени
- Формат записи: `{equipment_id, sensor_type, value, unit, timestamp, quality_flag}`

**Поток 2: Данные добычи (средняя частота)**
- Источник: операторы + автоматические весы + лаборатория
- Частота: по сменам (3 смены × 3 шахты = 9 записей/день) + лабораторные пробы
- Расчётный объём: ~50–100 записей/день
- Требования: целостность и точность данных, связь с оборудованием
- Формат записи: `{production_id, mine, horizon, date, shift, tonnage, fe_pct, moisture_pct, equipment_id, operator}`

**Поток 3: События простоев (событийный)**
- Источник: автоматические аларм-системы + ручной ввод диспетчерами
- Частота: по событию (5–20 событий/день)
- Требования: фиксация времени начала и окончания с точностью до минуты
- Формат записи: `{event_id, equipment_id, type, category, start_time, end_time, duration, severity, description}`

---

## Задание 2. Схема жизненного цикла данных

### 2.1. Шесть этапов жизненного цикла данных «Руда+»

```
┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────────┐    ┌──────────────┐
│  1. СБОР │───▸│2.ХРАНЕНИЕ│───▸│3.ОБРАБОТКА│──▸│ 4. АНАЛИЗ│───▸│5.ВИЗУАЛИЗАЦИЯ│───▸│6.АРХИВИРОВАНИЕ│
└──────────┘    └──────────┘    └──────────┘    └──────────┘    └──────────────┘    └──────────────┘
```

### Этап 1. Сбор данных (Data Collection)

| Компонент | Описание |
|---|---|
| **Датчики → Шлюзы IoT** | Показания датчиков оборудования поступают через MQTT-брокер. Шлюзы в каждой шахте агрегируют данные и передают на поверхность |
| **АСУ ТП → OPC UA сервер** | Данные управления процессами (скиповые подъёмники, вентиляция, конвейеры) через OPC UA |
| **Навигация → GPS-приёмники** | Координаты оборудования из подземной навигационной системы, передача через Wi-Fi точки в шахте |
| **ERP → REST API / файлы** | Данные о плановом ТО, складских остатках запчастей, нарядах-допусках. Выгрузка по расписанию (каждые 15 мин) или по событию |
| **Операторы → веб-формы** | Сменные рапорты через веб-интерфейс на планшетах. Заполняются в конце каждой смены |
| **Лаборатория → LIMS** | Результаты анализа проб руды. Выгружаются после подтверждения лаборантом |
| **Видеорегистраторы → NVR** | Непрерывная запись на сетевой видеорегистратор (NVR), хранение 30 дней |

**Валидация на входе:**
- Проверка формата и диапазонов значений датчиков (температура 0–200°C, давление 0–300 бар)
- Проверка timestamp (не из будущего, не старше 24 часов)
- Проверка наличия обязательных полей в сменных рапортах
- Дедупликация показаний (одинаковые timestamp + equipment_id)

### Этап 2. Хранение данных (Data Storage)

```
                         Архитектура хранения «Руда+»
                                    │
            ┌───────────────────────┼────────────────────────┐
            │                       │                        │
     Оперативное               Аналитическое             Архивное
     хранение                  хранение                  хранение
            │                       │                        │
  ┌─────────┴─────────┐   ┌────────┴────────┐     ┌────────┴────────┐
  │ TimescaleDB        │   │ PostgreSQL       │     │ Yandex Object   │
  │ (телеметрия,       │   │ (DWH, агрегаты,  │     │ Storage (S3)    │
  │  горячие данные    │   │  отчёты)         │     │ (видео, старые  │
  │  за 7 дней)        │   │                  │     │  данные)        │
  └────────────────────┘   └──────────────────┘     └─────────────────┘
  │ Redis               │   │ ClickHouse       │
  │ (кэш последних     │   │ (аналитика по    │
  │  значений, аларм)  │   │  телеметрии)     │
  └────────────────────┘   └──────────────────┘
```

| Тип хранения | Технология | Данные | Горизонт хранения |
|---|---|---|---|
| **Горячие** (оперативные) | TimescaleDB + Redis | Телеметрия текущая, статусы оборудования, аларм-буфер | 7 дней |
| **Тёплые** (аналитические) | PostgreSQL (Managed) | Справочники, журнал добычи, простои, агрегированная телеметрия | 1–5 лет |
| **Тёплые** (аналитические) | ClickHouse | Детальная телеметрия для анализа трендов | 1 год |
| **Холодные** (архивные) | Yandex Object Storage (S3) | Видеоархив, архив телеметрии старше 1 года, резервные копии | 3–7 лет |

### Этап 3. Обработка данных (Data Processing)

| Процесс | Подход | Описание | Инструменты |
|---|---|---|---|
| **Потоковая обработка телеметрии** | Stream (ELT) | Валидация, обогащение (добавление mine_id, equipment_name), расчёт скользящих средних, детекция аномалий | Apache Kafka + Kafka Streams |
| **Пакетная обработка добычи** | Batch (ETL) | Агрегация за смену/сутки, расчёт KPI, сверка с ERP | Apache Airflow + SQL |
| **Расчёт KPI оборудования** | Batch (ETL) | OEE, MTBF, MTTR — ежедневно по каждой единице | SQL + dbt |
| **Обработка видео** | Batch | Видеоаналитика (при наличии): детекция инцидентов, нарушений ТБ | Yandex Vision (опционально) |
| **Очистка данных** | Batch | Удаление дубликатов, заполнение пропусков (интерполяция для телеметрии), стандартизация единиц | Python / SQL |

**Правила обогащения данных:**
```
Телеметрия:
  показание датчика
    + equipment_id → equipment_name, equipment_type, mine_name (из справочника)
    + sensor_type + value → quality_flag (OK / WARN / ALARM по пороговым значениям)
    + timestamp → shift_number (1/2/3), production_date

Добыча:
  запись смены
    + operator_name → operator_id, qualification (из справочника)
    + mine_id + horizon → horizon_id, depth_m (из справочника)
    + tonnage + fe_content → quality_category (Высокосортная / Рядовая / Бедная)
```

### Этап 4. Анализ данных (Data Analysis)

| Тип аналитики | Вопрос | Методы | Пример для «Руда+» |
|---|---|---|---|
| **Описательная** | Что произошло? | Агрегации, отчёты, дашборды | «За февраль добыто 185 000 т руды, среднее Fe = 31.8%» |
| **Диагностическая** | Почему это произошло? | Drill-down, корреляции, root cause analysis | «Простой ПДМ-01 вызван перегревом двигателя — температура росла 2 часа до ALARM» |
| **Предиктивная** | Что произойдёт? | Тренды, ML-модели, прогнозирование | «По тренду вибрации СС-03 прогнозируется поломка подвески через 5–7 дней» |
| **Предписательная** | Что делать? | Оптимизация, рекомендательные системы | «Рекомендуется перенести ТО ПДМ-01 с 25.02 на 20.02 для предотвращения поломки» |

### Этап 5. Визуализация данных (Data Visualization)

| Дашборд | Аудитория | Содержание | Частота обновления |
|---|---|---|---|
| **Оперативный мониторинг** | Диспетчер | Карта шахты, статус оборудования, текущие аларм, температуры | Реальное время (5 сек) |
| **Суточный отчёт по добыче** | Начальник шахты | Тоннаж по сменам, качество руды, план/факт | Ежедневно утром |
| **Дашборд эффективности** | Руководство | OEE, MTBF, MTTR, добыча vs план, затраты на ТО | Еженедельно |
| **Аналитический отчёт** | Аналитик | Тренды телеметрии, корреляции, прогнозы | По запросу (self-service) |

**Инструменты визуализации:** Yandex DataLens (основной), Grafana (мониторинг телеметрии).

### Этап 6. Архивирование данных (Data Archiving)

| Тип данных | Горизонт хранения | Политика архивирования | Место архива |
|---|---|---|---|
| Детальная телеметрия | 1 год в БД | Агрегация до часовых средних → перенос в S3 | Yandex Object Storage (Cold) |
| Видеозаписи | 30 дней на NVR | Удаление по FIFO, инцидентные записи — 1 год | Yandex Object Storage (Cold) |
| Журнал добычи | 5 лет в БД | Перенос в архив после 5 лет | Yandex Object Storage |
| Простои и ТО | 5 лет в БД | Перенос в архив после 5 лет | Yandex Object Storage |
| Данные ERP | 7 лет | Согласно 402-ФЗ «О бухгалтерском учёте» | Архив ERP + Object Storage |

**Регуляторные требования:**
- 402-ФЗ: первичные документы — не менее 5 лет
- ФЗ-116 «О промышленной безопасности»: данные об авариях — 10 лет
- Внутренние стандарты компании: телеметрия аварий — бессрочно

---

## Задание 3. Политика Data Governance

### 3.1. Организационная структура управления данными

```
                    Комитет по управлению данными (Data Governance Council)
                                        │
                    ┌───────────────────┼───────────────────┐
                    │                   │                   │
             Chief Data Officer   Data Stewards        Data Owners
             (CDO)                (по доменам)         (бизнес-владельцы)
                    │                   │                   │
             Стратегия и         Качество и           Определение
             политики            стандарты              правил доступа
```

### 3.2. Роли и ответственность

| Роль | Кто в «Руда+» | Ответственность |
|---|---|---|
| **Data Owner** (Владелец данных) | Начальник шахты, Гл. механик, Гл. технолог | Определяет правила доступа, утверждает стандарты качества, отвечает за полноту данных домена |
| **Data Steward** (Распорядитель данных) | Инженер по данным, Ведущий аналитик | Следит за качеством данных, ведёт справочники, реагирует на инциденты |
| **Data Engineer** (Инженер данных) | ИТ-отдел | Реализует пайплайны, обеспечивает доступность, мониторинг |
| **Data Consumer** (Потребитель данных) | Аналитики, операторы, руководство | Использует данные для принятия решений |

### 3.3. Политики управления данными

#### Политика 1. Классификация данных

| Класс | Описание | Примеры | Доступ |
|---|---|---|---|
| **Открытые** | Общедоступная информация | Тип оборудования, названия шахт | Все сотрудники |
| **Внутренние** | Рабочая информация | Объёмы добычи, телеметрия, простои | Сотрудники по роли |
| **Конфиденциальные** | Чувствительная информация | Персональные данные операторов, зарплаты, финансы | Ограниченный круг |
| **Секретные** | Критически важные | Геологические карты рудных тел, запасы месторождения | Только руководство |

#### Политика 2. Управление справочниками (Master Data Management)

| Справочник | Владелец | Правила обновления |
|---|---|---|
| Справочник оборудования | Главный механик | Изменение только через заявку, утверждение Data Steward |
| Справочник шахт и горизонтов | Главный геолог | Изменение при вводе нового горизонта, утверждение начальника шахты |
| Справочник операторов | Отдел кадров | Синхронизация с кадровой системой 1 раз в сутки |
| Типы датчиков и пороговые значения | Главный механик + Инженер АСУ ТП | Изменение через комитет, тестирование новых порогов |

#### Политика 3. Качество данных

- Автоматическая проверка при загрузке: формат, диапазоны, полнота обязательных полей
- Ежедневный отчёт о качестве данных (Data Quality Report) с метриками по каждому источнику
- Процедура эскалации: если качество источника < 95%, Data Steward инициирует расследование
- Регулярный аудит справочников: ежеквартально

#### Политика 4. Безопасность данных

- Аутентификация: LDAP/Active Directory, двухфакторная для удалённого доступа
- Авторизация: ролевая модель (RBAC), минимальные привилегии
- Шифрование: данные в движении (TLS), данные в покое (AES-256 для конфиденциальных)
- Аудит: логирование всех операций доступа к данным, хранение логов 1 год
- Соответствие 152-ФЗ «О персональных данных» для данных об операторах

#### Политика 5. Управление изменениями

- Любое изменение структуры данных (DDL) — через pull request с ревью Data Steward
- Миграции БД через версионированные скрипты (Flyway / Liquibase)
- Обратная совместимость API: минимум 1 версия назад
- Документирование всех изменений в журнале изменений (Change Log)

---

## Задание 4. Ключевые метрики качества данных

### 4.1. Метрики по шести характеристикам качества

| Характеристика | Метрика | Формула / способ расчёта | Целевое значение | Пример нарушения |
|---|---|---|---|---|
| **Точность** (Accuracy) | Доля значений в допустимом диапазоне | `COUNT(valid) / COUNT(total) × 100%` | ≥ 99.5% | Датчик температуры показывает -50°C в шахте |
| **Полнота** (Completeness) | Доля заполненных обязательных полей | `COUNT(NOT NULL) / COUNT(total) × 100%` | ≥ 99% | Сменный рапорт без указания operator_name |
| **Согласованность** (Consistency) | Доля записей без противоречий между источниками | Сверка ERP ↔ MES, план ↔ факт | ≥ 98% | mine_name = «Северная» в equipment, но «Сев.» в ore_production |
| **Своевременность** (Timeliness) | Задержка поступления данных | `MAX(load_time - event_time)` | Телеметрия: < 5 сек, Рапорты: < 1 час | Показания датчиков приходят с задержкой 30 минут |
| **Уникальность** (Uniqueness) | Доля записей без дубликатов | `COUNT(DISTINCT) / COUNT(total) × 100%` | 100% | Один и тот же сменный рапорт загружен дважды |
| **Валидность** (Validity) | Доля записей, соответствующих правилам | Проверка CHECK-ограничений, формат | ≥ 99.5% | quality_flag = «ALARRM» (опечатка вместо «ALARM») |

### 4.2. Карточки метрик по источникам данных

**Источник: Телеметрия (датчики)**

| Метрика | Правило | Порог критичности |
|---|---|---|
| Точность значений | Значение в диапазоне: температура 0–200°C, давление 0–350 бар, вибрация 0–20 мм/с | < 99% → ALARM |
| Полнота потока | Нет пропусков показаний > 30 сек | > 5 мин без данных → ALARM |
| Своевременность | Задержка доставки < 5 секунд | > 30 сек → WARN |
| Уникальность | Нет дублей (equipment_id + timestamp) | Дубли > 1% → WARN |

**Источник: Сменные рапорты (ручной ввод)**

| Метрика | Правило | Порог критичности |
|---|---|---|
| Полнота | Все обязательные поля заполнены: тоннаж, Fe%, оператор, оборудование | < 100% → блокировка отправки |
| Своевременность | Рапорт сдан не позднее 1 часа после конца смены | > 2 часа → уведомление руководителю |
| Точность | Fe% в диапазоне 15–65%, тоннаж > 0, влажность 0–30% | Выход за диапазон → ручная проверка |
| Согласованность | Указанный оператор действительно работал в эту смену (сверка со СКУД) | Несоответствие → WARN |

### 4.3. Data Quality Dashboard (структура)

```
┌─────────────────────────────────────────────────────────────┐
│  DATA QUALITY DASHBOARD — «Руда+»          Дата: 2026-02-17│
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Общий индекс качества данных: ████████████░░ 92.4%        │
│                                                             │
│  По источникам:                                             │
│  ▸ Телеметрия         ████████████████░ 98.2%  ✅           │
│  ▸ Добыча (рапорты)   ████████████░░░░ 87.5%  ⚠️           │
│  ▸ Простои             ███████████████░ 95.1%  ✅           │
│  ▸ ERP                 ████████████████ 99.8%  ✅           │
│  ▸ Навигация           ██████████████░░ 91.3%  ⚠️           │
│                                                             │
│  Проблемы за последние 24 часа:                             │
│  ⚠️ 3 рапорта с пустым полем fe_content_pct                │
│  ⚠️ Датчик давления EQ-005 — нет данных 45 минут           │
│  ✅ Дубликатов не обнаружено                                │
│  ✅ Все рапорты поданы в срок                               │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

---

## Задание 5. Метаданные, которые необходимо фиксировать

### 5.1. Технические метаданные

| Категория | Что фиксируем | Пример |
|---|---|---|
| **Схема данных** | Названия таблиц, столбцов, типы данных, ограничения | `equipment.engine_hours: NUMERIC(10,1), NOT NULL, CHECK >= 0` |
| **Индексы** | Имя индекса, столбцы, тип (B-tree, Hash), уникальность | `idx_sensor_equipment_time ON sensor_readings(equipment_id, reading_timestamp)` |
| **Статистика** | Объём таблиц (строки, байты), кардинальность столбцов | `sensor_readings: 50 000 000 строк, 12 ГБ, equipment_id: 50 уникальных` |
| **Зависимости** | FK-связи, представления, функции, триггеры | `ore_production.equipment_id → equipment.equipment_id` |
| **ETL-конфигурация** | Расписание, источник, приёмник, маппинг полей | `Airflow DAG: erp_to_dwh, запуск: 06:00 UTC, источник: ERP API, приёмник: PostgreSQL` |
| **Data Lineage** | Цепочка трансформаций от источника до отчёта | `Датчик → MQTT → Kafka → TimescaleDB → dbt (агрегация) → PostgreSQL → DataLens` |

### 5.2. Бизнес-метаданные

| Категория | Что фиксируем | Пример |
|---|---|---|
| **Бизнес-глоссарий** | Определения терминов на бизнес-языке | «Fe% — содержание железа в руде, измеряется в процентах от массы, определяется лабораторным анализом» |
| **Владельцы данных** | Роль, ФИО, домен ответственности | «Справочник оборудования: Data Owner — Главный механик Зайцев К.К.» |
| **Бизнес-правила** | Правила расчёта показателей | «OEE = Доступность × Производительность × Качество. Доступность = (Плановое время - Простои) / Плановое время» |
| **Классификация** | Уровень конфиденциальности | «ore_production → Внутренние данные, operators.salary → Конфиденциальные» |
| **SLA** | Гарантированные характеристики | «Телеметрия: задержка < 5 сек, доступность 99.5%, потери < 0.1%» |

### 5.3. Операционные метаданные

| Категория | Что фиксируем | Пример |
|---|---|---|
| **Время загрузки** | Дата и время последней успешной загрузки | `sensor_readings: последняя загрузка 2026-02-17 08:45:12 UTC` |
| **Результат проверки качества** | Статус DQ-проверки, количество ошибок | `ore_production 2026-02-16: PASS, ошибок: 0, предупреждений: 2` |
| **Логи ETL** | Статус, длительность, количество обработанных записей | `DAG telemetry_hourly_agg: SUCCESS, 00:03:42, 3 600 000 записей → 60 000 агрегатов` |
| **Инциденты** | Инциденты с данными, их причины и решения | `2026-02-15: Датчик вибрации EQ-003 передавал нули 2 часа. Причина: обрыв кабеля. Решено: замена кабеля, данные интерполированы` |
| **Использование** | Кто и как часто обращается к данным | `Таблица ore_production: 45 запросов/день, основные потребители: DataLens (30), Аналитики (15)` |

### 5.4. Каталог данных (Data Catalog) — пример записи

```
┌───────────────────────────────────────────────────────────┐
│  КАТАЛОГ ДАННЫХ — sensor_readings                         │
├───────────────────────────────────────────────────────────┤
│  Бизнес-описание: Показания датчиков горнодобывающего     │
│  оборудования. Основа для мониторинга состояния           │
│  и предиктивной аналитики.                                │
│                                                           │
│  Владелец:        Главный механик (Data Owner)            │
│  Распорядитель:   Инженер по данным (Data Steward)        │
│  Классификация:   Внутренние данные                       │
│  Схема:           ruda_plus.sensor_readings               │
│  Формат:          PostgreSQL таблица                      │
│  Объём:           ~50 млн строк/день                      │
│  Хранение:        TimescaleDB (7 дней) → ClickHouse (1 г)│
│  Обновление:      Реальное время (1–10 сек)               │
│  Качество:        DQ-индекс 98.2% (за последний месяц)    │
│                                                           │
│  Lineage:                                                 │
│  Датчик → MQTT брокер → Kafka topic → Stream Processing   │
│  → TimescaleDB → dbt (агрегация) → PostgreSQL DWH         │
│  → DataLens (дашборд мониторинга)                         │
│                                                           │
│  Связанные таблицы:                                       │
│  ▸ equipment (FK: equipment_id)                           │
│  ▸ downtime_events (корреляция по equipment_id + time)    │
│                                                           │
│  Последнее обновление каталога: 2026-02-17                │
└───────────────────────────────────────────────────────────┘
```

---

## Итоги

| Задание | Ключевые выводы |
|---|---|
| **1. Источники данных** | 8 источников: от высокочастотной телеметрии (50 млн записей/день) до ручных рапортов (50 записей/день). Три типа: структурированные, полуструктурированные, неструктурированные |
| **2. Жизненный цикл** | 6 этапов: Сбор (IoT/SCADA/ERP) → Хранение (горячее/тёплое/холодное) → Обработка (потоковая + пакетная) → Анализ (4 типа аналитики) → Визуализация (4 дашборда) → Архивирование (по политикам хранения) |
| **3. Data Governance** | 4 роли (Owner, Steward, Engineer, Consumer), 5 политик (классификация, MDM, качество, безопасность, управление изменениями) |
| **4. Метрики качества** | 6 характеристик × метрики по каждому источнику, пороги критичности, Data Quality Dashboard |
| **5. Метаданные** | Три категории: технические (схемы, lineage), бизнес (глоссарий, владельцы, SLA), операционные (логи ETL, инциденты, использование). Каталог данных как центральное хранилище метаданных |
